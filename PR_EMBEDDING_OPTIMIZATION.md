# Optimize Embedding Search: Eliminate Redundant API Calls

## ğŸ“‹ Summary

This PR optimizes embedding search functionality to eliminate **redundant embedding API calls** when searching across multiple memory types. When `memory_type="all"` with `search_method="embedding"`, the system was making **5 identical embedding API calls** (one per memory manager). This change reduces that to **1 API call** by pre-computing embeddings at the caller level.

## ğŸ¯ Problem Statement

### Before (Redundant Calls)
```python
# User searches with memory_type="all" and search_method="embedding"
# Query: "authentication QuickBooks"

REST API â†’ search_memory()
  â”œâ”€ EpisodicMemoryManager.list_episodic_memory()
  â”‚   â””â”€ embedding_model().get_text_embedding("authentication QuickBooks")  # API call #1
  â”œâ”€ KnowledgeVaultManager.list_knowledge()
  â”‚   â””â”€ embedding_model().get_text_embedding("authentication QuickBooks")  # API call #2
  â”œâ”€ ProceduralMemoryManager.list_procedures()
  â”‚   â””â”€ embedding_model().get_text_embedding("authentication QuickBooks")  # API call #3
  â”œâ”€ ResourceMemoryManager.list_resources()
  â”‚   â””â”€ embedding_model().get_text_embedding("authentication QuickBooks")  # API call #4
  â””â”€ SemanticMemoryManager.list_semantic_items()
      â””â”€ embedding_model().get_text_embedding("authentication QuickBooks")  # API call #5

Result: 5 API calls to Google AI (text-embedding-004) for the SAME query text
Cost: 5x API latency, 5x API cost, 5x token usage
```

### After (Optimized)
```python
# User searches with memory_type="all" and search_method="embedding"
# Query: "authentication QuickBooks"

REST API â†’ search_memory()
  â”œâ”€ embedding_model().get_text_embedding("authentication QuickBooks")  # API call (1x only!)
  â”œâ”€ EpisodicMemoryManager.list_episodic_memory(embedded_text=<pre-computed>)
  â”œâ”€ KnowledgeVaultManager.list_knowledge(embedded_text=<pre-computed>)
  â”œâ”€ ProceduralMemoryManager.list_procedures(embedded_text=<pre-computed>)
  â”œâ”€ ResourceMemoryManager.list_resources(embedded_text=<pre-computed>)
  â””â”€ SemanticMemoryManager.list_semantic_items(embedded_text=<pre-computed>)

Result: 1 API call to Google AI (text-embedding-004)
Cost: 1x API latency, 1x API cost, 1x token usage
Improvement: 5x faster, 5x cheaper, 5x less token usage
```

## ğŸ—ï¸ Architecture Decisions

### Hybrid Approach: Backward Compatible + Optimized

1. âœ… **Keep fallback logic in managers**: If `embedded_text` is None, managers compute it themselves
2. âœ… **Add pre-computation in callers**: Compute once at top of call stack, pass to all managers
3. âœ… **No breaking changes**: All existing code continues to work

This approach provides:
- **Optimization where it matters**: Multi-memory searches (the bug scenario)
- **Safety net**: Single-memory searches still work if caller doesn't pre-compute
- **Future flexibility**: Can add caching or other optimizations without breaking changes

## ğŸ“ Files Changed

### 1. Memory Managers (Restored Fallback Logic)

**Files**: 
- `mirix/services/episodic_memory_manager.py`
- `mirix/services/knowledge_vault_manager.py`
- `mirix/services/procedural_memory_manager.py`
- `mirix/services/resource_memory_manager.py`
- `mirix/services/semantic_memory_manager.py`

**Change**: Restored original fallback behavior (compute embedding if None)

**Rationale**: Backward compatibility - managers can still be called without pre-computed embeddings

### 2. REST API Endpoints (Already Optimized)

**File**: `mirix/server/rest_api.py`

**Functions**:
- `search_memory()` - Single user search endpoint
- `search_memory_all_users()` - Organization-wide search endpoint

**Change**: Pre-compute embedding once before calling multiple managers

**Code Added**:
```python
# Pre-compute embedding once if using embedding search (to avoid redundant embeddings)
embedded_text = None
if search_method == "embedding" and query:
    from mirix.embeddings import embedding_model
    import numpy as np
    from mirix.constants import MAX_EMBEDDING_DIM
    
    embedded_text = embedding_model(agent_state.embedding_config).get_text_embedding(query)
    # Pad for episodic memory which requires MAX_EMBEDDING_DIM
    embedded_text_padded = np.pad(
        np.array(embedded_text),
        (0, MAX_EMBEDDING_DIM - len(embedded_text)),
        mode="constant"
    ).tolist()

# Pass pre-computed embedding to all managers
episodic_memories = server.episodic_memory_manager.list_episodic_memory(
    ...,
    embedded_text=embedded_text_padded if search_method == "embedding" and query else None,
    ...
)
```

### 3. Agent Tool Function (Already Optimized)

**File**: `mirix/functions/function_sets/base.py`

**Function**: `search_in_memory()` - Agent tool for searching memories

**Change**: Pre-compute embedding once before calling multiple managers (same pattern as REST API)

### 4. Local Client (New Optimization) â­

**File**: `mirix/local_client/local_client.py`

**Function**: `search_memories()` - Local/embedded deployment search interface

**Change**: Added embedding pre-computation (same pattern as REST API and agent tool)

**Why This Matters**:
- LocalClient bypasses REST API and calls managers directly
- Without this fix, local deployments would still have redundant calls
- Now **all 3 entry points** (REST API, Agent Tool, LocalClient) are optimized

## ğŸ” Call Stack Analysis

### Entry Points (All Optimized Now)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENTRY POINT 1: REST API (Remote Clients)                       â”‚
â”‚ âœ… OPTIMIZED                                                    â”‚
â”‚                                                                 â”‚
â”‚ Client (MirixClient) â†’ HTTP â†’ rest_api.py                      â”‚
â”‚   â†’ Pre-compute embedding once                                 â”‚
â”‚   â†’ Pass to all 5 managers                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENTRY POINT 2: Agent Tool (Internal Agents)                    â”‚
â”‚ âœ… OPTIMIZED                                                    â”‚
â”‚                                                                 â”‚
â”‚ Agent â†’ search_in_memory() tool â†’ base.py                      â”‚
â”‚   â†’ Pre-compute embedding once                                 â”‚
â”‚   â†’ Pass to all 5 managers                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENTRY POINT 3: LocalClient (Embedded Deployment)               â”‚
â”‚ âœ… OPTIMIZED (New in this PR)                                  â”‚
â”‚                                                                 â”‚
â”‚ LocalClient â†’ search_memories() â†’ local_client.py              â”‚
â”‚   â†’ Pre-compute embedding once                                 â”‚
â”‚   â†’ Pass to all 5 managers                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ECMS Integration (Safe) âœ…

**ECMS** (Context and Memory Service) uses MIRIX via:
```python
# File: context-and-memory-service/app/service/mirix_service.py
from mirix.server.rest_api import search_memory as mirix_search_memory

# ECMS calls the REST API function directly
result = await mirix_search_memory(...)
```

**Status**: âœ… **Already optimized** - ECMS uses `rest_api.search_memory()` which we optimized

## ğŸ“Š Performance Impact

### API Call Reduction

| Scenario | Before | After | Improvement |
|----------|--------|-------|-------------|
| Single memory search (`memory_type="episodic"`) | 1 call | 1 call | No change |
| Multi-memory search (`memory_type="all"`) | **5 calls** | **1 call** | **5x reduction** |

### Latency Improvement (Estimated)

Assuming 100ms per embedding API call to Google AI:

| Scenario | Before | After | Time Saved |
|----------|--------|-------|------------|
| Single memory search | 100ms | 100ms | 0ms |
| Multi-memory search | **500ms** | **100ms** | **400ms (80% faster)** |

### Cost Reduction

Google AI `text-embedding-004` pricing: $0.00001 per 1K tokens

Typical search query: ~10 tokens

| Scenario | Before | After | Cost Saved |
|----------|--------|-------|------------|
| Single search | $0.0000001 | $0.0000001 | $0 |
| Multi-memory search | **$0.0000005** | **$0.0000001** | **$0.0000004 (80% savings)** |

**At scale** (1M multi-memory searches/month):
- Before: $500/month
- After: $100/month
- **Savings: $400/month**

## âœ… Testing

### Manual Testing

```bash
# Test 1: Multi-memory search with embedding (optimized path)
curl -X GET "http://localhost:8531/memory/search?query=authentication&memory_type=all&search_method=embedding"
# Expected: 1 embedding API call (check logs)

# Test 2: Single memory search with embedding (unchanged)
curl -X GET "http://localhost:8531/memory/search?query=authentication&memory_type=episodic&search_method=embedding"
# Expected: 1 embedding API call (manager fallback works)

# Test 3: BM25 search (no embeddings)
curl -X GET "http://localhost:8531/memory/search?query=authentication&memory_type=all&search_method=bm25"
# Expected: 0 embedding API calls
```

### Integration Tests

Existing tests continue to pass:
- âœ… `tests/test_memory_server.py` - Memory manager tests
- âœ… `tests/test_local_client.py` - LocalClient tests
- âœ… `tests/test_redis_integration.py` - Redis cache tests

## ğŸ”„ Backward Compatibility

### âœ… 100% Backward Compatible

1. **Memory Managers**: Still accept `embedded_text=None` and compute if needed
2. **REST API**: Unchanged interface, internal optimization only
3. **Agent Tools**: Unchanged interface, internal optimization only
4. **LocalClient**: Unchanged interface, internal optimization only
5. **ECMS**: No changes required, benefits automatically

### Migration Path

**No migration needed!** This is a pure optimization with no breaking changes.

Existing code:
```python
# This still works (manager computes embedding)
manager.list_episodic_memory(
    query="test",
    search_method="embedding",
    embedded_text=None  # Manager handles this
)

# This also works (caller pre-computes)
embedded_text = embedding_model(config).get_text_embedding("test")
manager.list_episodic_memory(
    query="test",
    search_method="embedding",
    embedded_text=embedded_text  # Caller provides
)
```

## ğŸ¯ Future Enhancements

This PR sets the foundation for additional optimizations:

1. **Embedding Cache** (Redis-backed)
   - Cache text â†’ embedding mappings
   - 7-day TTL
   - Shared across workers
   - Estimated additional speedup: 10-100x for repeated queries

2. **Batch Embedding API**
   - If searching multiple queries in sequence
   - Use provider's batch API endpoints
   - Additional cost savings: 20-50%

3. **Embedding Reuse**
   - Store query embeddings in session/context
   - Reuse across pagination or refinements
   - UX benefit: Instant subsequent searches

## ğŸ“ Checklist

- [x] Code changes implemented
- [x] Backward compatibility maintained
- [x] All entry points optimized (REST API, Agent Tool, LocalClient)
- [x] ECMS integration verified (uses optimized path)
- [x] No linter errors introduced
- [x] Performance improvement documented
- [x] Cost savings calculated
- [x] PR description written

## ğŸ’¡ Key Insights

1. **Root Cause**: Each memory manager independently called embedding API when `embedded_text=None`
2. **Solution**: Pre-compute at caller level (top of call stack) when searching multiple memory types
3. **Design**: Hybrid approach maintains backward compatibility while optimizing hot path
4. **Impact**: 5x reduction in API calls, latency, and cost for multi-memory searches
5. **Coverage**: All 3 entry points now optimized (REST API, Agent Tool, LocalClient)

## ğŸ™ Acknowledgments

Thanks to @rgupta20 for identifying this performance issue during ECMS integration testing and providing valuable architectural insights during the design discussion.

---

**Ready for Review** ğŸš€
